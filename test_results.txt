============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.5, pluggy-1.5.0
rootdir: /home/fit-sizhe/dwhelper/gtc
plugins: anyio-4.9.0
collected 35 items

tests/run_single_test.py .FF                                             [  8%]
tests/test_llm_generators.py ........FFFF.FFF.F                          [ 60%]
tests/test_pipeline.py ...........                                       [ 91%]
tests/test_scene_detector.py .                                           [ 94%]
tests/test_scene_processor.py F                                          [ 97%]
tests/test_summary_generator.py F                                        [100%]

=================================== FAILURES ===================================
_____________________________ test_scene_processor _____________________________

test_video_path = '/home/fit-sizhe/dwhelper/gtc/vid/distributed-light-baking-system-powered-by-optix-7.mp4'
test_output_dir = '/home/fit-sizhe/dwhelper/gtc/tests/output'

    def test_scene_processor(test_video_path, test_output_dir):
        """Test the SceneProcessor stage with sample scenes."""
    
        # Create processor output directory
        processor_output_dir = os.path.join(test_output_dir, "processor_output")
        os.makedirs(processor_output_dir, exist_ok=True)
    
        # Load or create sample scenes
        sample_scenes_file = os.path.join(
            test_output_dir, "scenes_test.json")
        pipeline_result_file = os.path.join(
            test_output_dir, "scenes_test_pipeline_result.json")
    
        if os.path.exists(pipeline_result_file):
            print(f"Loading PipelineResult from {pipeline_result_file}")
            with open(pipeline_result_file, 'r') as f:
                data = json.load(f)
            # Convert to PipelineResult
            result = PipelineResult.from_dict(data)
            scenes = result.scenes
    
        elif os.path.exists(sample_scenes_file):
            print(f"Loading sample scenes from {sample_scenes_file}")
            with open(sample_scenes_file, 'r') as f:
                scene_dicts = json.load(f)
            # Convert dict to Scene objects
            scenes = [Scene(
                scene_id=s["scene_id"],
                start=s["start"],
                end=s["end"]
            ) for s in scene_dicts]
    
            # Create a PipelineResult with the scenes
            result = PipelineResult(
                video_path=test_video_path,
                scenes=scenes
            )
        else:
            # Create some sample scenes manually
            print("Sample scenes file not found, creating sample scenes")
            scenes = [
                Scene(scene_id=1, start=10.0, end=20.0),
                Scene(scene_id=2, start=30.0, end=40.0),
                Scene(scene_id=3, start=50.0, end=60.0)
            ]
    
            # Create a PipelineResult with the scenes
            result = PipelineResult(
                video_path=test_video_path,
                scenes=scenes
            )
    
        # Process only the first few scenes to save time
        if len(scenes) > 30:
            scenes_to_process = scenes[:30]
            result.scenes = scenes_to_process
            print(f"Processing {len(scenes_to_process)} out of {len(scenes)} scenes")
        else:
            print(f"Processing all {len(scenes)} scenes")
    
        # Create and run SceneProcessor
        processor = create_scene_processor(
            output_dir=processor_output_dir,
            use_whisper=True
        )
    
        # Process the scenes
>       processed_result = processor.run(result)

tests/test_scene_processor.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <video_summarizer.stages.scene_processor.SceneProcessor object at 0x7ee07b1c9840>
data = PipelineResult(video_path='/home/fit-sizhe/dwhelper/gtc/vid/distributed-light-baking-system-powered-by-optix-7.mp4', s...d=1381.425, screenshot=None, transcript=None)], output_dir=None, summary_file=None, complete_summary=None, metadata={})

    def run(self, data: PipelineResult) -> PipelineResult:
        video_path = data.video_path
        scenes = data.scenes
    
        if not video_path:
            raise ValueError("Input must contain video_path")
    
        if not os.path.exists(video_path):
>           raise FileNotFoundError(f"Video file not found: {video_path}")
E           FileNotFoundError: Video file not found: /home/fit-sizhe/dwhelper/gtc/vid/distributed-light-baking-system-powered-by-optix-7.mp4

video_summarizer/stages/scene_processor.py:38: FileNotFoundError
----------------------------- Captured stdout call -----------------------------
Loading sample scenes from /home/fit-sizhe/dwhelper/gtc/tests/output/scenes_test.json
Processing all 22 scenes
____________________________ test_summary_generator ____________________________

test_output_dir = '/home/fit-sizhe/dwhelper/gtc/tests/output'
provider = 'anthropic'

    def test_summary_generator(test_output_dir, provider="anthropic"):
        """Test the LLMSummaryGenerator with sample processed scenes."""
    
        # Path for the test summary file
        test_summary_file = os.path.join(test_output_dir, f"test_summary_{provider}.md")
    
        # Load processed scenes from previous test or create sample
        processed_scenes_file = os.path.join(
            test_output_dir, "processed_scenes.json")
    
        if os.path.exists(processed_scenes_file):
            print(f"Loading processed scenes from {processed_scenes_file}")
            with open(processed_scenes_file, 'r') as f:
                data = json.load(f)
    
            # Convert to PipelineResult
>           result = PipelineResult.from_dict(data)

tests/test_summary_generator.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'video_summarizer.core.data_classes.PipelineResult'>
data = [{'end': 214.6302063498281, 'scene_id': 1, 'screenshot': '/home/fit-sizhe/dwhelper/gtc/tests/output/processor_output/s...e/fit-sizhe/dwhelper/gtc/tests/output/processor_output/screenshots/scene_6.jpg', 'start': 728.0281139443791, ...}, ...]

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'PipelineResult':
        """Create PipelineResult object from dictionary."""
        result = cls(
>           video_path=data["video_path"],
            output_dir=data.get("output_dir"),
            summary_file=data.get("summary_file"),
            complete_summary=data.get("complete_summary"),
            metadata=data.get("metadata", {})
        )
E       TypeError: list indices must be integers or slices, not str

video_summarizer/core/data_classes.py:69: TypeError
----------------------------- Captured stdout call -----------------------------
Loading processed scenes from /home/fit-sizhe/dwhelper/gtc/tests/output/processed_scenes.json
___________________ TestGeminiGenerator.test_initialization ____________________

self = <tests.test_llm_generators.TestGeminiGenerator object at 0x7ee07b1c8ee0>

    def test_initialization(self):
        """Test that GeminiGenerator initializes correctly."""
        with patch.dict(os.environ, {"GEMINI_API_KEY": "test_key"}):
>           with patch("google.generativeai") as mock_genai:

tests/test_llm_generators.py:232: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7ee060d1c8b0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'google' (<_frozen_importlib_external._NamespaceLoader object at 0x7ee08d3912d0>)> does not have the attribute 'generativeai'

/usr/lib/python3.10/unittest/mock.py:1420: AttributeError
____________________ TestGeminiGenerator.test_is_available _____________________

self = <tests.test_llm_generators.TestGeminiGenerator object at 0x7ee07b1c9060>

    def test_is_available(self):
        """Test the is_available method."""
        # Test when API key is available
        with patch.dict(os.environ, {"GEMINI_API_KEY": "test_key"}):
>           with patch("google.generativeai"):

tests/test_llm_generators.py:246: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7ee060d17b80>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'google' (<_frozen_importlib_external._NamespaceLoader object at 0x7ee08d3912d0>)> does not have the attribute 'generativeai'

/usr/lib/python3.10/unittest/mock.py:1420: AttributeError
_____________ TestGeminiGenerator.test_generate_content_with_image _____________

self = <tests.test_llm_generators.TestGeminiGenerator object at 0x7ee07b1c91e0>

    def test_generate_content_with_image(self):
        """Test generating content with an image."""
        with patch.dict(os.environ, {"GEMINI_API_KEY": "test_key"}):
            # Create mocks for Gemini
            mock_genai = MagicMock()
            mock_model = MagicMock()
            mock_response = MagicMock()
    
            mock_response.text = "Generated text from Gemini"
            mock_model.generate_content.return_value = mock_response
            mock_genai.GenerativeModel.return_value = mock_model
    
>           with patch("google.generativeai", mock_genai):

tests/test_llm_generators.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7ee060d441c0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'google' (<_frozen_importlib_external._NamespaceLoader object at 0x7ee08d3912d0>)> does not have the attribute 'generativeai'

/usr/lib/python3.10/unittest/mock.py:1420: AttributeError
_____________ TestGeminiGenerator.test_generate_content_text_only ______________

self = <tests.test_llm_generators.TestGeminiGenerator object at 0x7ee07b1c9360>

    def test_generate_content_text_only(self):
        """Test generating content with text only."""
        with patch.dict(os.environ, {"GEMINI_API_KEY": "test_key"}):
            # Create mocks for Gemini
            mock_genai = MagicMock()
            mock_model = MagicMock()
            mock_response = MagicMock()
    
            mock_response.text = "Generated text from Gemini"
            mock_model.generate_content.return_value = mock_response
            mock_genai.GenerativeModel.return_value = mock_model
    
>           with patch("google.generativeai", mock_genai):

tests/test_llm_generators.py:298: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.10/unittest/mock.py:1447: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <unittest.mock._patch object at 0x7ee060d525c0>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'google' (<_frozen_importlib_external._NamespaceLoader object at 0x7ee08d3912d0>)> does not have the attribute 'generativeai'

/usr/lib/python3.10/unittest/mock.py:1420: AttributeError
____ TestLLMSummaryGenerator.test_initialization_with_limited_availability _____

self = <tests.test_llm_generators.TestLLMSummaryGenerator object at 0x7ee07b1c96f0>

    def test_initialization_with_limited_availability(self):
        """Test initialization when preferred provider is not available."""
        # Only OpenAI available
        with patch("video_summarizer.llm_providers.get_available_llm_providers",
                 return_value={"anthropic": False, "openai": True, "gemini": False}):
            # Mock generator initializations
            with patch("video_summarizer.llm_providers.AnthropicGenerator"):
                with patch("video_summarizer.llm_providers.OpenAIGenerator"):
                    with patch("video_summarizer.llm_providers.GeminiGenerator"):
                        # Prefer Anthropic, should fall back to OpenAI
                        generator = LLMSummaryGenerator(preferred_provider="anthropic")
>                       assert generator.active_provider == "openai"
E                       AssertionError: assert 'anthropic' == 'openai'
E                         
E                         - openai
E                         + anthropic

tests/test_llm_generators.py:352: AssertionError
----------------------------- Captured stdout call -----------------------------
Available LLM providers: anthropic, openai, gemini
Using ANTHROPIC as the primary LLM provider
___________ TestLLMSummaryGenerator.test_initialization_no_providers ___________

self = <tests.test_llm_generators.TestLLMSummaryGenerator object at 0x7ee07b1c9870>

    def test_initialization_no_providers(self):
        """Test initialization when no providers are available."""
        with patch("video_summarizer.llm_providers.get_available_llm_providers",
                 return_value={"anthropic": False, "openai": False, "gemini": False}):
            # Should raise ValueError
>           with pytest.raises(ValueError) as excinfo:
E           Failed: DID NOT RAISE <class 'ValueError'>

tests/test_llm_generators.py:360: Failed
----------------------------- Captured stdout call -----------------------------
Available LLM providers: anthropic, openai, gemini
Using GEMINI as the primary LLM provider
_____________ TestLLMSummaryGenerator.test_generate_scene_summary ______________

self = <tests.test_llm_generators.TestLLMSummaryGenerator object at 0x7ee07b1c99f0>

    def test_generate_scene_summary(self):
        """Test the _generate_scene_summary method."""
        # Mock available providers
        with patch("video_summarizer.llm_providers.get_available_llm_providers",
                 return_value={"anthropic": True, "openai": True, "gemini": False}):
            # Create mocks for content generation
            mock_anthropic_generator = MagicMock()
            mock_anthropic_generator.generate_content.return_value = "Summary from Anthropic"
    
            mock_openai_generator = MagicMock()
            mock_openai_generator.generate_content.return_value = "Summary from OpenAI"
    
            # Create the generator with mocked providers
            with patch("video_summarizer.llm_providers.AnthropicGenerator", return_value=mock_anthropic_generator):
                with patch("video_summarizer.llm_providers.OpenAIGenerator", return_value=mock_openai_generator):
                    with patch("video_summarizer.llm_providers.GeminiGenerator"):
                        generator = LLMSummaryGenerator(preferred_provider="anthropic")
                        generator.active_provider = "anthropic"
                        generator.available_generators = ["anthropic", "openai"]
    
                        # Mock the _encode_image method
                        with patch.object(generator, "_encode_image", return_value="encoded_image"):
                            # Test successful generation with primary provider
                            result = generator._generate_scene_summary(
                                scene_id=1,
                                screenshot_path="test.jpg",
                                transcript="Test transcript",
                                start_time=0.0,
                                end_time=10.0,
                                scene_index=0,
                                total_scenes=3
                            )
    
                            # Verify the result
>                           assert result == "Summary from Anthropic"
E                           AssertionError: assert '*Error gener...LM providers*' == 'Summary from Anthropic'
E                             
E                             - Summary from Anthropic
E                             + *Error generating summary for scene 1 after trying all available LLM providers*

tests/test_llm_generators.py:398: AssertionError
----------------------------- Captured stdout call -----------------------------
Available LLM providers: anthropic, openai, gemini
Using ANTHROPIC as the primary LLM provider
Attempting to generate summary for scene 1 using ANTHROPIC (attempt 1/3)...
Error generating summary with ANTHROPIC for scene 1 (attempt 1/3): Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.0.content.0.image.source.base64: invalid base64 data'}}
Retrying in 2.41 seconds...
Attempting to generate summary for scene 1 using ANTHROPIC (attempt 2/3)...
Error generating summary with ANTHROPIC for scene 1 (attempt 2/3): Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.0.content.0.image.source.base64: invalid base64 data'}}
Retrying in 4.34 seconds...
Attempting to generate summary for scene 1 using ANTHROPIC (attempt 3/3)...
Error generating summary with ANTHROPIC for scene 1 (attempt 3/3): Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'messages.0.content.0.image.source.base64: invalid base64 data'}}
All attempts with ANTHROPIC failed. Trying next provider...
Attempting to generate summary for scene 1 using OPENAI (attempt 1/3)...
Error generating summary with OPENAI for scene 1 (attempt 1/3): Error code: 400 - {'error': {'message': "You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_format'}}
Retrying in 2.22 seconds...
Attempting to generate summary for scene 1 using OPENAI (attempt 2/3)...
Error generating summary with OPENAI for scene 1 (attempt 2/3): Error code: 400 - {'error': {'message': "You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_format'}}
Retrying in 4.12 seconds...
Attempting to generate summary for scene 1 using OPENAI (attempt 3/3)...
Error generating summary with OPENAI for scene 1 (attempt 3/3): Error code: 400 - {'error': {'message': "You uploaded an unsupported image. Please make sure your image has of one the following formats: ['png', 'jpeg', 'gif', 'webp'].", 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_format'}}
All attempts with OPENAI failed. Trying next provider...
___________________ TestLLMSummaryGenerator.test_run_method ____________________

self = <tests.test_llm_generators.TestLLMSummaryGenerator object at 0x7ee07b1c9cf0>

    def test_run_method(self):
        """Test the run method with a simple scene."""
        # Create a mock scene
        scene = Scene(
            scene_id=1,
            start=0.0,
            end=10.0,
            screenshot="/path/to/screenshot.jpg",
            transcript="Test transcript"
        )
    
        # Create pipeline result input
        input_data = PipelineResult(
            video_path="test_video.mp4",
            scenes=[scene],
            output_dir="/tmp/test_output"
        )
    
        # Mock the generator initialization
        with patch("video_summarizer.llm_providers.get_available_llm_providers",
                 return_value={"anthropic": True, "openai": False, "gemini": False}):
            # Mock generator initialization
            with patch("video_summarizer.llm_providers.AnthropicGenerator") as mock_anthropic:
                with patch("video_summarizer.llm_providers.OpenAIGenerator"):
                    with patch("video_summarizer.llm_providers.GeminiGenerator"):
                        # Setup mock anthropic generator
                        mock_instance = MagicMock()
                        mock_instance.generate_content.return_value = "Test summary"
                        mock_anthropic.return_value = mock_instance
    
                        # Create the generator
                        generator = LLMSummaryGenerator(
                            output_dir="/tmp/test_output"
                        )
    
                        # Mock file operations
                        with patch("os.makedirs"):
                            with patch("builtins.open", MagicMock()):
                                # Run the generator
>                               result = generator.run(input_data)

tests/test_llm_generators.py:486: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
video_summarizer/stages/summary_generator.py:116: in run
    scene_summary = self._generate_scene_summary(
video_summarizer/stages/summary_generator.py:181: in _generate_scene_summary
    base64_image = self._encode_image(screenshot_path)
video_summarizer/stages/summary_generator.py:170: in _encode_image
    return base64.b64encode(img_file.read()).decode("utf-8")
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

s = <MagicMock name='mock().__enter__().read()' id='139502120277456'>
altchars = None

    def b64encode(s, altchars=None):
        """Encode the bytes-like object s using Base64 and return a bytes object.
    
        Optional altchars should be a byte string of length 2 which specifies an
        alternative alphabet for the '+' and '/' characters.  This allows an
        application to e.g. generate url or filesystem safe Base64 strings.
        """
>       encoded = binascii.b2a_base64(s, newline=False)
E       TypeError: a bytes-like object is required, not 'MagicMock'

/usr/lib/python3.10/base64.py:58: TypeError
----------------------------- Captured stdout call -----------------------------
Available LLM providers: anthropic, openai, gemini
Using GEMINI as the primary LLM provider
Generating summaries with GEMINI API for 1 scenes...
Processing scene 1 (0.00s - 10.00s) with GEMINI...
_____________________________ test_scene_processor _____________________________

test_video_path = '/home/fit-sizhe/dwhelper/gtc/vid/distributed-light-baking-system-powered-by-optix-7.mp4'
test_output_dir = '/home/fit-sizhe/dwhelper/gtc/tests/output'

    def test_scene_processor(test_video_path, test_output_dir):
        """Test the SceneProcessor stage with sample scenes."""
    
        # Create processor output directory
        processor_output_dir = os.path.join(test_output_dir, "processor_output")
        os.makedirs(processor_output_dir, exist_ok=True)
    
        # Load or create sample scenes
        sample_scenes_file = os.path.join(
            test_output_dir, "scenes_test.json")
        pipeline_result_file = os.path.join(
            test_output_dir, "scenes_test_pipeline_result.json")
    
        if os.path.exists(pipeline_result_file):
            print(f"Loading PipelineResult from {pipeline_result_file}")
            with open(pipeline_result_file, 'r') as f:
                data = json.load(f)
            # Convert to PipelineResult
            result = PipelineResult.from_dict(data)
            scenes = result.scenes
    
        elif os.path.exists(sample_scenes_file):
            print(f"Loading sample scenes from {sample_scenes_file}")
            with open(sample_scenes_file, 'r') as f:
                scene_dicts = json.load(f)
            # Convert dict to Scene objects
            scenes = [Scene(
                scene_id=s["scene_id"],
                start=s["start"],
                end=s["end"]
            ) for s in scene_dicts]
    
            # Create a PipelineResult with the scenes
            result = PipelineResult(
                video_path=test_video_path,
                scenes=scenes
            )
        else:
            # Create some sample scenes manually
            print("Sample scenes file not found, creating sample scenes")
            scenes = [
                Scene(scene_id=1, start=10.0, end=20.0),
                Scene(scene_id=2, start=30.0, end=40.0),
                Scene(scene_id=3, start=50.0, end=60.0)
            ]
    
            # Create a PipelineResult with the scenes
            result = PipelineResult(
                video_path=test_video_path,
                scenes=scenes
            )
    
        # Process only the first few scenes to save time
        if len(scenes) > 30:
            scenes_to_process = scenes[:30]
            result.scenes = scenes_to_process
            print(f"Processing {len(scenes_to_process)} out of {len(scenes)} scenes")
        else:
            print(f"Processing all {len(scenes)} scenes")
    
        # Create and run SceneProcessor
        processor = create_scene_processor(
            output_dir=processor_output_dir,
            use_whisper=True
        )
    
        # Process the scenes
>       processed_result = processor.run(result)

tests/test_scene_processor.py:86: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <video_summarizer.stages.scene_processor.SceneProcessor object at 0x7ee05e9afb80>
data = PipelineResult(video_path='/home/fit-sizhe/dwhelper/gtc/vid/distributed-light-baking-system-powered-by-optix-7.mp4', s...d=1381.425, screenshot=None, transcript=None)], output_dir=None, summary_file=None, complete_summary=None, metadata={})

    def run(self, data: PipelineResult) -> PipelineResult:
        video_path = data.video_path
        scenes = data.scenes
    
        if not video_path:
            raise ValueError("Input must contain video_path")
    
        if not os.path.exists(video_path):
>           raise FileNotFoundError(f"Video file not found: {video_path}")
E           FileNotFoundError: Video file not found: /home/fit-sizhe/dwhelper/gtc/vid/distributed-light-baking-system-powered-by-optix-7.mp4

video_summarizer/stages/scene_processor.py:38: FileNotFoundError
----------------------------- Captured stdout call -----------------------------
Loading sample scenes from /home/fit-sizhe/dwhelper/gtc/tests/output/scenes_test.json
Processing all 22 scenes
____________________________ test_summary_generator ____________________________

test_output_dir = '/home/fit-sizhe/dwhelper/gtc/tests/output'
provider = 'anthropic'

    def test_summary_generator(test_output_dir, provider="anthropic"):
        """Test the LLMSummaryGenerator with sample processed scenes."""
    
        # Path for the test summary file
        test_summary_file = os.path.join(test_output_dir, f"test_summary_{provider}.md")
    
        # Load processed scenes from previous test or create sample
        processed_scenes_file = os.path.join(
            test_output_dir, "processed_scenes.json")
    
        if os.path.exists(processed_scenes_file):
            print(f"Loading processed scenes from {processed_scenes_file}")
            with open(processed_scenes_file, 'r') as f:
                data = json.load(f)
    
            # Convert to PipelineResult
>           result = PipelineResult.from_dict(data)

tests/test_summary_generator.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'video_summarizer.core.data_classes.PipelineResult'>
data = [{'end': 214.6302063498281, 'scene_id': 1, 'screenshot': '/home/fit-sizhe/dwhelper/gtc/tests/output/processor_output/s...e/fit-sizhe/dwhelper/gtc/tests/output/processor_output/screenshots/scene_6.jpg', 'start': 728.0281139443791, ...}, ...]

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'PipelineResult':
        """Create PipelineResult object from dictionary."""
        result = cls(
>           video_path=data["video_path"],
            output_dir=data.get("output_dir"),
            summary_file=data.get("summary_file"),
            complete_summary=data.get("complete_summary"),
            metadata=data.get("metadata", {})
        )
E       TypeError: list indices must be integers or slices, not str

video_summarizer/core/data_classes.py:69: TypeError
----------------------------- Captured stdout call -----------------------------
Loading processed scenes from /home/fit-sizhe/dwhelper/gtc/tests/output/processed_scenes.json
=========================== short test summary info ============================
FAILED tests/run_single_test.py::test_scene_processor - FileNotFoundError: Vi...
FAILED tests/run_single_test.py::test_summary_generator - TypeError: list ind...
FAILED tests/test_llm_generators.py::TestGeminiGenerator::test_initialization
FAILED tests/test_llm_generators.py::TestGeminiGenerator::test_is_available
FAILED tests/test_llm_generators.py::TestGeminiGenerator::test_generate_content_with_image
FAILED tests/test_llm_generators.py::TestGeminiGenerator::test_generate_content_text_only
FAILED tests/test_llm_generators.py::TestLLMSummaryGenerator::test_initialization_with_limited_availability
FAILED tests/test_llm_generators.py::TestLLMSummaryGenerator::test_initialization_no_providers
FAILED tests/test_llm_generators.py::TestLLMSummaryGenerator::test_generate_scene_summary
FAILED tests/test_llm_generators.py::TestLLMSummaryGenerator::test_run_method
FAILED tests/test_scene_processor.py::test_scene_processor - FileNotFoundErro...
FAILED tests/test_summary_generator.py::test_summary_generator - TypeError: l...
======================== 12 failed, 23 passed in 18.10s ========================
